{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9d4560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#Can build a model two ways. Either by calling the model or building it incrementally\n",
    "\n",
    "#Call model\n",
    "model = keras.Sequential([layers.Dense(64, activation = \"relu\"),\n",
    "                         layers.Dense(10, activation = \"softmax\")\n",
    "                         ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7bb0d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_6/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.28506237, -0.23297027,  0.01497746, -0.26703653,  0.13593277,\n",
       "         -0.10515498, -0.28276533, -0.14928101, -0.00583535,  0.17064166,\n",
       "          0.29534596, -0.12115157,  0.2109999 , -0.15897106, -0.03347385,\n",
       "         -0.08763362,  0.2686414 , -0.27470708, -0.13745447, -0.18214199,\n",
       "          0.17653087,  0.21565115, -0.25642985, -0.23058519, -0.00032878,\n",
       "          0.07611236,  0.13333187,  0.2756433 ,  0.07663348,  0.24783015,\n",
       "         -0.05329724,  0.16841662, -0.00095856, -0.25447145,  0.03814861,\n",
       "          0.00667349,  0.11731943,  0.0260936 ,  0.07198021, -0.14284234,\n",
       "         -0.03221244,  0.07890242, -0.2349152 , -0.28132442, -0.05373146,\n",
       "         -0.230812  ,  0.24572045, -0.12761344,  0.03106394, -0.2466868 ,\n",
       "         -0.16670127, -0.15189733,  0.24619353,  0.21693808,  0.01848185,\n",
       "          0.18113828,  0.10281971,  0.00801766, -0.26555407, -0.2645883 ,\n",
       "          0.21138   , -0.21002735,  0.23362851,  0.16379508],\n",
       "        [-0.16122471, -0.0814179 ,  0.14088705, -0.23509842,  0.11784241,\n",
       "         -0.2832199 ,  0.26071763,  0.10249928,  0.07804397,  0.16151688,\n",
       "          0.18297854,  0.23753607, -0.02183801,  0.06948027,  0.06846064,\n",
       "          0.05839652,  0.17458993,  0.16001609,  0.00601345,  0.19847378,\n",
       "          0.19631267,  0.10729513,  0.18111289, -0.00417581, -0.26016405,\n",
       "          0.12135991,  0.00399461,  0.19565612,  0.16736108, -0.10335553,\n",
       "          0.1094282 , -0.04927717,  0.18288401, -0.11801128, -0.27730718,\n",
       "          0.29422098,  0.22600204,  0.11705837,  0.12044346,  0.07238188,\n",
       "          0.22395891,  0.05446178,  0.02951649, -0.24472696,  0.06436929,\n",
       "         -0.21234643,  0.24930924, -0.26387852, -0.21093325,  0.21558118,\n",
       "          0.24466366,  0.22248822,  0.2664739 ,  0.03081366,  0.29095286,\n",
       "         -0.22540659,  0.1552256 ,  0.03420252, -0.1810277 ,  0.1472668 ,\n",
       "         -0.18571272, -0.20986804, -0.0085853 , -0.13465251],\n",
       "        [-0.20972106,  0.19920039,  0.13179648, -0.21469298, -0.01769817,\n",
       "         -0.29387665, -0.05872014,  0.23554724, -0.26569596,  0.22037989,\n",
       "         -0.119201  , -0.14978908,  0.17883754,  0.12217882, -0.20887217,\n",
       "          0.2659971 ,  0.15053588, -0.27887028,  0.14143887,  0.2584564 ,\n",
       "          0.29608524,  0.10217893,  0.2499215 , -0.09913555, -0.13549334,\n",
       "          0.18435925,  0.03633267,  0.27889228, -0.29790592, -0.17711115,\n",
       "          0.01725158,  0.1219371 , -0.2349244 ,  0.12991688,  0.00587118,\n",
       "         -0.14115654, -0.0992808 , -0.12044802,  0.27710158, -0.23501244,\n",
       "          0.01461744, -0.1723171 , -0.10237508, -0.13316263,  0.2521835 ,\n",
       "          0.16177788, -0.23970689, -0.21662629, -0.06612337,  0.05842471,\n",
       "         -0.28323802,  0.24461675,  0.19097194, -0.07086669, -0.21726505,\n",
       "          0.01123801,  0.07746625, -0.02389953, -0.04682082,  0.19614208,\n",
       "          0.19388285, -0.28751615, -0.09169893,  0.22239679]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_6/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_7/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[ 0.19269383,  0.26524273, -0.26331562,  0.20074195,  0.03401467,\n",
       "          0.24497369,  0.09757987, -0.27186882, -0.2710101 , -0.2273309 ],\n",
       "        [-0.14174531,  0.08847943, -0.26953828,  0.09469208, -0.1187022 ,\n",
       "         -0.13990633,  0.19153807,  0.2750292 ,  0.10395846, -0.05120003],\n",
       "        [ 0.20993736, -0.21528086, -0.01343721, -0.08823013,  0.20174947,\n",
       "         -0.21303949,  0.10357198,  0.22118643, -0.05884394,  0.22094491],\n",
       "        [ 0.19008762, -0.01332274, -0.06521322,  0.27346775,  0.15791214,\n",
       "          0.01705015, -0.08463113,  0.0111495 ,  0.1384874 ,  0.19782448],\n",
       "        [-0.03324562, -0.12923288,  0.11228091,  0.24992093,  0.2804375 ,\n",
       "         -0.01986089, -0.01903996, -0.09508109,  0.07215285,  0.24354789],\n",
       "        [ 0.00886089, -0.02791896, -0.08337368,  0.03439519, -0.09492962,\n",
       "          0.00787568, -0.1564566 ,  0.11155117,  0.02570558, -0.06791201],\n",
       "        [ 0.2674056 ,  0.08421835, -0.15843251, -0.22381708, -0.07377139,\n",
       "          0.02763125, -0.06222583, -0.2304715 , -0.25637153, -0.2505565 ],\n",
       "        [ 0.02225444,  0.08454892,  0.17982131, -0.25450993, -0.01118657,\n",
       "         -0.26209146, -0.12617299, -0.01655373,  0.00401109, -0.08971187],\n",
       "        [ 0.0545938 ,  0.05568349,  0.11763784,  0.16271937,  0.08285502,\n",
       "          0.05914047, -0.24164496,  0.06589103,  0.0199469 ,  0.14436087],\n",
       "        [ 0.19914186,  0.06116602,  0.25462225, -0.04834428,  0.05047306,\n",
       "          0.2726418 , -0.11250067,  0.2199029 ,  0.11290514,  0.18234622],\n",
       "        [-0.08206321,  0.10350069, -0.27364537, -0.21176365, -0.23207831,\n",
       "         -0.16093932, -0.02246225,  0.16256967, -0.06405836, -0.11154276],\n",
       "        [ 0.19118235, -0.25204983, -0.06350818, -0.24683766, -0.06701119,\n",
       "         -0.27642488, -0.2582416 ,  0.16903394,  0.03395417, -0.03325778],\n",
       "        [-0.06817597, -0.11151852,  0.09552822,  0.22328666, -0.20965481,\n",
       "          0.04433176,  0.2596369 ,  0.1664063 ,  0.08633101, -0.04524711],\n",
       "        [ 0.24561921, -0.20962122,  0.2418119 , -0.18834499,  0.18568304,\n",
       "         -0.2496385 ,  0.026521  , -0.11074506, -0.01029062, -0.0551213 ],\n",
       "        [-0.10725923, -0.09298141,  0.23883638,  0.10118935, -0.04373474,\n",
       "          0.01213497,  0.1902585 ,  0.00614253,  0.10744843,  0.16799477],\n",
       "        [ 0.06477901,  0.2099255 ,  0.20945096, -0.00323126, -0.1952789 ,\n",
       "          0.14932641,  0.1037482 , -0.15219697, -0.2682365 , -0.16750887],\n",
       "        [ 0.18031147, -0.00464326,  0.14938691, -0.18697879,  0.26367316,\n",
       "          0.14202976,  0.271094  ,  0.20919195,  0.14078909, -0.02883649],\n",
       "        [-0.24674079,  0.09637091, -0.18884797, -0.2336462 , -0.19526729,\n",
       "          0.04990342,  0.2197912 , -0.2754246 , -0.14681575, -0.1433811 ],\n",
       "        [-0.13170548, -0.05331586, -0.00832176,  0.05474499,  0.0611707 ,\n",
       "         -0.14824976, -0.17440891,  0.16279235,  0.12942407,  0.20404068],\n",
       "        [ 0.28073236,  0.06576476, -0.07442556, -0.28089544,  0.2107282 ,\n",
       "         -0.24987176, -0.12299448, -0.15570928, -0.22223303, -0.00378618],\n",
       "        [ 0.26741335, -0.22001605, -0.05587983,  0.2739677 , -0.11414631,\n",
       "          0.14991388,  0.16024739,  0.01306212,  0.24919906,  0.00743264],\n",
       "        [-0.05814305,  0.05762368, -0.18032199, -0.12512709,  0.25584528,\n",
       "         -0.13957803, -0.05723211, -0.18364991,  0.06659293,  0.25935385],\n",
       "        [-0.12014614, -0.13851726,  0.04154614,  0.00691253,  0.02639583,\n",
       "         -0.17225087,  0.28135553, -0.12527326, -0.20779622,  0.27864245],\n",
       "        [-0.03475846,  0.17266601,  0.0658181 ,  0.00275859,  0.2399461 ,\n",
       "          0.0500322 , -0.10544421,  0.16391408, -0.15528484,  0.10326001],\n",
       "        [ 0.04259902,  0.14404023,  0.09056315, -0.02903092,  0.01145688,\n",
       "         -0.2770927 ,  0.17124921, -0.1486176 ,  0.06172338, -0.13183881],\n",
       "        [-0.08531789,  0.27336958, -0.20033528, -0.0498307 , -0.18899617,\n",
       "         -0.26919624, -0.21294676,  0.18656221,  0.09279466,  0.06703815],\n",
       "        [-0.12792791,  0.25539938,  0.25881484,  0.24746898, -0.10975225,\n",
       "         -0.17666739,  0.24159166, -0.14778751,  0.135741  , -0.08699143],\n",
       "        [-0.10439567,  0.19512826,  0.09576908, -0.00462174, -0.11078036,\n",
       "         -0.00403091, -0.09064738, -0.10258506, -0.27691734, -0.11302538],\n",
       "        [ 0.236429  , -0.18673858,  0.2465094 ,  0.19883996,  0.17551816,\n",
       "          0.28396097, -0.14831215, -0.09354347, -0.27088812,  0.21044925],\n",
       "        [ 0.15762877, -0.2602801 ,  0.26116887, -0.11066855,  0.26081708,\n",
       "         -0.25364232, -0.09877676, -0.09026456,  0.24626055, -0.00591016],\n",
       "        [ 0.03021681, -0.11912854, -0.1590882 ,  0.1339904 , -0.13554989,\n",
       "          0.2086842 ,  0.06705457,  0.24442747, -0.18953691,  0.07134524],\n",
       "        [ 0.09633732,  0.11694577, -0.25937405,  0.214793  ,  0.06462368,\n",
       "         -0.08015119,  0.27199218, -0.00189695, -0.07166207, -0.05354594],\n",
       "        [ 0.18113619, -0.01707837,  0.1985147 , -0.23993084,  0.08182791,\n",
       "          0.0719316 ,  0.08549258,  0.08827901,  0.26121792,  0.20860654],\n",
       "        [ 0.16723466,  0.05606857, -0.25927535,  0.03429517, -0.2272918 ,\n",
       "          0.24711892,  0.07219663,  0.00751987, -0.18279159, -0.03687674],\n",
       "        [ 0.08890671,  0.00673065, -0.20103447,  0.1445188 ,  0.04821977,\n",
       "         -0.03648366, -0.236289  ,  0.01182601,  0.22195032, -0.20262912],\n",
       "        [ 0.2098563 ,  0.18145627, -0.02699777, -0.2172607 ,  0.16101265,\n",
       "         -0.22088945, -0.10533844, -0.141768  , -0.14192611,  0.02377313],\n",
       "        [-0.06129989,  0.02606186,  0.17300022, -0.19352974,  0.1456964 ,\n",
       "         -0.26376098, -0.12062082, -0.2644965 ,  0.20017052,  0.20537537],\n",
       "        [-0.1508377 , -0.07120083,  0.16387966,  0.22369489,  0.02823657,\n",
       "         -0.10253178, -0.02292329, -0.15966035,  0.18739724,  0.17473641],\n",
       "        [ 0.27938703, -0.262322  ,  0.08750126,  0.20276406, -0.13350928,\n",
       "         -0.19610491,  0.00044405, -0.00130197,  0.18843907,  0.00799108],\n",
       "        [-0.02995396, -0.097923  ,  0.13590175,  0.07035601, -0.16587071,\n",
       "          0.13015434, -0.01372594,  0.16663957, -0.18386105, -0.16754961],\n",
       "        [ 0.16637948,  0.20350283,  0.05906191,  0.05291042, -0.20028001,\n",
       "         -0.2439352 , -0.19231133, -0.23243296, -0.11615738,  0.04390827],\n",
       "        [ 0.02890256,  0.21529517,  0.2602308 ,  0.16034666, -0.2302085 ,\n",
       "          0.07512286, -0.21522403,  0.00264597,  0.03662777, -0.07098027],\n",
       "        [-0.13376673, -0.08024114,  0.06932744, -0.17626637,  0.02579206,\n",
       "         -0.16158922, -0.06955235, -0.1954673 ,  0.03216544,  0.12886682],\n",
       "        [ 0.2501342 ,  0.16937032, -0.14498404, -0.0141865 , -0.27159443,\n",
       "          0.05444315,  0.2667844 , -0.20431793,  0.2764913 ,  0.23461041],\n",
       "        [-0.0998008 , -0.19892292,  0.09862509,  0.17449343, -0.2300656 ,\n",
       "         -0.16110599,  0.09764349, -0.12892182,  0.26445642,  0.13189515],\n",
       "        [ 0.24472848,  0.1087676 , -0.04154491, -0.20348269,  0.28028932,\n",
       "          0.07869598, -0.1331361 ,  0.00078622,  0.2009308 , -0.15737331],\n",
       "        [ 0.082728  , -0.2075229 , -0.17812143, -0.0015009 ,  0.07463452,\n",
       "          0.23167464, -0.16196044,  0.00890136, -0.00961852, -0.08682734],\n",
       "        [-0.2493211 ,  0.00603506,  0.15316269, -0.05911522, -0.02399769,\n",
       "         -0.22470352, -0.21407032,  0.17749673,  0.23360172,  0.02341935],\n",
       "        [ 0.04496822,  0.0286555 , -0.15210749,  0.05498669,  0.21739623,\n",
       "          0.14415836, -0.21367168,  0.08641723, -0.05941685,  0.14446333],\n",
       "        [ 0.26361313,  0.07126072,  0.26967147, -0.03411981,  0.05187783,\n",
       "          0.0278005 ,  0.04105246,  0.04297522,  0.2481806 , -0.11413042],\n",
       "        [-0.19095802,  0.24888697,  0.02867213, -0.08236478,  0.21279034,\n",
       "         -0.2825721 ,  0.1664486 ,  0.20412791, -0.18361318,  0.13727596],\n",
       "        [-0.13533367, -0.03558223,  0.09763977, -0.00486046,  0.06203818,\n",
       "         -0.19753146, -0.20869026, -0.20641753, -0.27760893,  0.2618139 ],\n",
       "        [-0.02984011,  0.23446414, -0.20361745,  0.22910121,  0.18136796,\n",
       "          0.01135206, -0.02538231,  0.0835422 , -0.11870702,  0.28095773],\n",
       "        [ 0.14406163, -0.25896236, -0.26291025, -0.26671553, -0.06536672,\n",
       "         -0.12386109, -0.16890645,  0.2084398 , -0.11656804,  0.02300557],\n",
       "        [-0.16971275,  0.12238744,  0.13608655, -0.01828301, -0.26444578,\n",
       "          0.0104799 , -0.18387502,  0.15516216,  0.25776026, -0.2668834 ],\n",
       "        [ 0.17144549, -0.19716431,  0.02487999,  0.2023496 ,  0.22755119,\n",
       "         -0.26474997, -0.2192269 , -0.09438685,  0.0869056 , -0.25170797],\n",
       "        [-0.25708166, -0.21180981, -0.0406957 , -0.0658251 ,  0.14918017,\n",
       "         -0.24348381,  0.00869414, -0.22711569,  0.02559668,  0.03112599],\n",
       "        [ 0.22574523, -0.17531502,  0.04378816,  0.2814683 ,  0.16355297,\n",
       "          0.13944435, -0.11695854, -0.2660536 ,  0.01896963,  0.19559574],\n",
       "        [-0.0792613 , -0.12910539,  0.20495036, -0.17821798, -0.03900214,\n",
       "         -0.21922201, -0.04849601, -0.24754316,  0.10501462,  0.22764072],\n",
       "        [ 0.11282513, -0.08294217,  0.2314497 ,  0.12512138,  0.09220931,\n",
       "          0.20053366,  0.24605295, -0.24599828,  0.19888252,  0.12076059],\n",
       "        [-0.27184296, -0.23927319, -0.12889263,  0.18150672,  0.18407258,\n",
       "         -0.28291324, -0.10493152,  0.11470577, -0.08185922, -0.04275389],\n",
       "        [-0.0193553 ,  0.03953844,  0.20400488,  0.23470923, -0.10806677,\n",
       "          0.06656563, -0.14517209, -0.07095812,  0.08443865,  0.05897346],\n",
       "        [ 0.23736748, -0.11101893, -0.20222728,  0.02705005,  0.25158104,\n",
       "         -0.06099385, -0.22592287, -0.21532878,  0.2594947 , -0.21761256],\n",
       "        [ 0.21685663, -0.20926948,  0.06097069,  0.12270862,  0.08589989,\n",
       "          0.15123993, -0.12267819, -0.20024247,  0.09744057,  0.00945219]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_7/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build model incrementally - these are equivalent\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation = \"relu\"))\n",
    "model.add(layers.Dense(10, activation = \"softmax\"))\n",
    "#However it does not have any weights unitl you call the build function\n",
    "model.build(input_shape = (None, 3))\n",
    "model.weights\n",
    "#Now the model expects samples of shape (3,) where None indicated that the batch size could be anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b2c120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Display model contents\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3adf9d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Example Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "First_Layer (Dense)          (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "Last_Layer (Dense)           (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Models and layers can be named\n",
    "model = keras.Sequential(name = \"Example Model\")\n",
    "model.add(layers.Dense(64, activation = \"relu\", name = \"First_Layer\"))\n",
    "model.add(layers.Dense(10, activation = \"softmax\", name = \"Last_Layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "879d0852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Rather than calling the build function everytime to declare input shape you can use the Input class\n",
    "model = keras.Sequential()\n",
    "#in this case the shape argument must be the shape of each sample, not the shape of one batch.\n",
    "#i.e. keras does not care about the sample size, sample feature size is whats being considered.\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation = \"relu\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "647d14b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (None, 3)\n",
      "Inputs dtype:  <dtype: 'float32'>\n",
      "Features Shape:  (None, 64)\n"
     ]
    }
   ],
   "source": [
    "#simple functional model with two dense layers\n",
    "#inputs hold information about shape/dtype model will process - called symbolic tensor\n",
    "inputs = keras.Input(shape=(3,), name = \"my_input\")\n",
    "print(\"Input shape: \",inputs.shape)\n",
    "print(\"Inputs dtype: \", inputs.dtype)\n",
    "#Create a layer and called it on input\n",
    "#All layers can be called on both real tensors of data and symbolic tensors with layers updating shape/dtype when called on symbolic tensors\n",
    "features = layers.Dense(64, activation = \"relu\")(inputs)\n",
    "print(\"Features Shape: \", features.shape)\n",
    "outputs = layers.Dense(10, activation = \"softmax\")(features)\n",
    "#started model by specifying inputs/outputs\n",
    "model = keras.Model(inputs = inputs, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bac22a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rank customer support tickets by priority and route to appropriate department.\n",
    "#Ticket contains: title, text body, tags added by user (categorical input)\n",
    "#Model would have two outputs - priority score of ticket (scaler between 0/1) and department that should handle it (softmax)\n",
    "vocab_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "title = keras.Input(shape=(vocab_size,), name = \"title\")\n",
    "text_body = keras.Input(shape=(vocab_size,), name = \"text_body\")\n",
    "tags = keras.Input(shape = (num_tags,), name = \"tags\")\n",
    "#Combine inputs into a single tensor (features) by concatenating\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "#Intermediate later to recombine input features into richer representations \n",
    "features = layers.Dense(64, activation = \"relu\")(features)\n",
    "#Next two lines define the model output\n",
    "priority = layers.Dense(1, activation = \"sigmoid\", name = \"priority\")(features)\n",
    "department = layers.Dense(num_departments, activation = \"softmax\", name = \"department\")(features)\n",
    "#Create model by specifiying inputs and outputs\n",
    "model = keras.Model(inputs = [title, text_body, tags], outputs = [priority, department])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8ab8415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 3s 9ms/step - loss: 30.2405 - priority_loss: 0.3208 - department_loss: 29.9198 - priority_mean_absolute_error: 0.4834 - department_accuracy: 0.2344\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 28.6573 - priority_loss: 0.3251 - department_loss: 28.3321 - priority_mean_absolute_error: 0.4875 - department_accuracy: 0.1203\n"
     ]
    }
   ],
   "source": [
    "#create dummy input/target data\n",
    "import numpy as np\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size = (num_samples, vocab_size))\n",
    "text_body_data = np.random.randint(0, 2, size = (num_samples, vocab_size))\n",
    "tags_data = np.random.randint(0, 2, size = (num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size = (num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size = (num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer = \"rmsprop\", loss = [\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics = [[\"mean_absolute_error\"], [\"accuracy\"]]) \n",
    "model.fit([title_data, text_body_data, tags_data], \n",
    "         [priority_data, department_data],\n",
    "         epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "              [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dd03075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 10ms/step - loss: 40.8857 - priority_loss: 0.3251 - department_loss: 40.5605 - priority_mean_absolute_error: 0.4875 - department_accuracy: 0.2562\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 52.2257 - priority_loss: 0.3251 - department_loss: 51.9006 - priority_mean_absolute_error: 0.4875 - department_accuracy: 0.0617\n"
     ]
    }
   ],
   "source": [
    "#Can also train model using a dictionary input based on the names of input objects.\n",
    "#Useful for when you dont want to rely on input order.\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\":\n",
    "                    \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\":\n",
    "                       [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96038430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bugged and not working right now...\n",
    "\n",
    "#keras.utils.plot_model(model, \"ticket_classifier.png\",  show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54737dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee2fdd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x223c57c9e50>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x223c57c9ee0>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x223c57c9400>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x223c5895c10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x223c588c970>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x223c58933a0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x223c5793580>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Allows inspection/reuse of indiv layers\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "804a7d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x223c588c970>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40762577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d6acade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These commands allow for feature extraction - creating models that reuse intermediate features from another model.\n",
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00ba3cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='dense_15/Relu:0', description=\"created by layer 'dense_15'\")\n"
     ]
    }
   ],
   "source": [
    "#Create model reusing intermediate layer outputs\n",
    "#add another classification layer that takes into account how quick the ticket would take to resolve\n",
    "features = model.layers[4].output\n",
    "#this is the layer after the concatenated one that recombines all the input features \n",
    "print(features)\n",
    "#difficulty == how long to complete ticket\n",
    "difficulty = layers.Dense(3, activation = \"softmax\", name = \"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(inputs = [title, text_body, tags],\n",
    "                       outputs = [priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43dcf3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On top of being able to subclass individual layers, models can also be subclassed\n",
    "class CustomerTicketModel(keras.Model):\n",
    "  \n",
    "    def __init__(self, num_departments):\n",
    "        #calls the super constructor\n",
    "        super().__init__()\n",
    "        #Defines the sublayers in the constructor\n",
    "        self.concat_layer = layers.Concatenate()                     \n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")      \n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\") \n",
    "        self.department_classifier = layers.Dense(                   \n",
    "            num_departments, activation=\"softmax\")\n",
    "    #Defines the forward pass in the call method\n",
    "    def call(self, inputs):                                          \n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "  \n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51072208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like the layer subclassing method this will only define the weights the first time it is called on data\n",
    "model = CustomerTicketModel(num_departments = 4)\n",
    "\n",
    "priority, department = model({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5540de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 10ms/step - loss: 28.1956 - output_1_loss: 0.3188 - output_2_loss: 27.8768 - output_1_mean_absolute_error: 0.4799 - output_2_accuracy: 0.2242\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 39.4919 - output_1_loss: 0.3251 - output_2_loss: 39.1668 - output_1_mean_absolute_error: 0.4875 - output_2_accuracy: 0.1203\n"
     ]
    }
   ],
   "source": [
    "#the structure of loss/metrics must match what gets returned by call() i.e. list of two elements\n",
    "model.compile(optimizer = \"rmsprop\", loss = [\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics = [[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "#structure of input data must match what is expected by the call() method i.e. dict w/ keys title, txtbody, tags\n",
    "model.fit({\"title\": title_data,\n",
    "          \"text_body\": text_body_data,\n",
    "          \"tags\": tags_data},\n",
    "        #Structure of target data much match what is returned by the call(). i.e. list of two elements\n",
    "         [priority_data, department_data],\n",
    "         epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "               \"text_body\": text_body_data,\n",
    "               \"tags\": tags_data},\n",
    "              [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                 \"text_body\": text_body_data,\n",
    "                                                 \"tags\": tags_data})\n",
    "#Subclassing allows more flexability for example a for loop inside the call() method to go through the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b92bd5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras allows subclassed models/layers to work with functional models\n",
    "class Classifier(keras.Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation = activation)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation = \"relu\")(inputs)\n",
    "outputs = Classifier(num_classes = 10)(features)\n",
    "model = keras.Model(inputs = inputs, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0884827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#or inversly use a functional model as part of a subclassed layer/model\n",
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, num_classes = 2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation = \"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "    \n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a03d96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can write your own metrics using subclassing. But the varaibles are not updated during backpropogation\n",
    "#so the state update logic has to be written yourself. \n",
    "import tensorflow as tf\n",
    "#subclass metrics class\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "    #define the state variables in constructor and access add_weight() method\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(name = \"total_samples\", initializer = \"zeros\", dtype = \"int32\")\n",
    "    #implement update state logic. y_true is the targets/labels for one batch\n",
    "    #y_pred is the predictions from the model.\n",
    "    #sample weight can be ignored.\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        #make categorical pred/labels to match model\n",
    "        y_true = tf.one_hot(y_true, depth = tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "        \n",
    "#use result() method to return current val of metric\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "#Need to reset metric state w/o reinstantiating it so can be used w/ diff epochs of training or both train/eval\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)\n",
    "#This class can be called when you are compiling your model in the metrics section of the list. \n",
    "#i.e. metrics = [\"accuracy\", RootMeanSquaredError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ffd250a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2913 - accuracy: 0.9127 - val_loss: 0.1573 - val_accuracy: 0.9523\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1640 - accuracy: 0.9540 - val_loss: 0.1298 - val_accuracy: 0.9650\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1382 - accuracy: 0.9622 - val_loss: 0.1123 - val_accuracy: 0.9720\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9721\n"
     ]
    }
   ],
   "source": [
    "#Test model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "  \n",
    "def get_mnist_model():                                                \n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "  \n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()      \n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255 \n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255 \n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "  \n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",                                    \n",
    "              loss=\"sparse_categorical_crossentropy\",                 \n",
    "              metrics=[\"accuracy\"])                                   \n",
    "model.fit(train_images, train_labels,                                 \n",
    "          epochs=3,                                                   \n",
    "          validation_data=(val_images, val_labels))                   \n",
    "test_metrics = model.evaluate(test_images, test_labels)               \n",
    "predictions = model.predict(test_images) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2342f614",
   "metadata": {},
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d8a4366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2913 - accuracy: 0.9153 - val_loss: 0.1516 - val_accuracy: 0.9563\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1641 - accuracy: 0.9539 - val_loss: 0.1235 - val_accuracy: 0.9664\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1387 - accuracy: 0.9626 - val_loss: 0.1136 - val_accuracy: 0.9718\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1248 - accuracy: 0.9676 - val_loss: 0.1169 - val_accuracy: 0.9717\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1159 - accuracy: 0.9698 - val_loss: 0.0973 - val_accuracy: 0.9769\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1110 - accuracy: 0.9725 - val_loss: 0.1082 - val_accuracy: 0.9768\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1037 - accuracy: 0.9750 - val_loss: 0.1071 - val_accuracy: 0.9782\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1051 - accuracy: 0.9756 - val_loss: 0.1217 - val_accuracy: 0.9757\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0962 - accuracy: 0.9791 - val_loss: 0.1187 - val_accuracy: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x223f771c1c0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#callback - an object thats is passed to the model in the call to fit()\n",
    "#and called by the model at various points during training. It has info on state of model/performance\n",
    "#and can be used to save, interrupt, load a different weight set, or otherwise alter the state of the model\n",
    "#can be used to checkpoint during training, early stopping, dynamically adjust the value of certain parameters during training,\n",
    "#like learning rate, logging training/validation metrics during training and visualize the representations learned by the model as they are updated.\n",
    "\n",
    "#use early stop and checkpoint call backs\n",
    "#callbacks are passed to the model vias the callbacks arg in fit() which takes a list.\n",
    "callbacks_list = [keras.callbacks.EarlyStopping(\n",
    "                monitor = \"val_accuracy\", patience = 2),\n",
    "                #saves current weights after each epoch\n",
    "                 keras.callbacks.ModelCheckpoint(\n",
    "                 filepath = \"checkpoint_path.keras\",\n",
    "                 monitor = \"val_loss\",\n",
    "                #wont overwrite file unless their is an improvement\n",
    "                 save_best_only = True)]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer = \"rmsprop\",\n",
    "             loss = \"sparse_categorical_crossentropy\",\n",
    "             metrics = [\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "         epochs = 10, callbacks = callbacks_list,\n",
    "         validation_data = (val_images, val_labels))\n",
    "\n",
    "#models can be saved manually using model.save('my_checkpoint_path')\n",
    "#to reload - model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a480df",
   "metadata": {},
   "source": [
    "## Custom Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c01d0399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1563 [..............................] - ETA: 24:05 - loss: 2.4534 - accuracy: 0.0938WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0040s vs `on_train_batch_end` time: 0.0043s). Check your callbacks.\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2969 - accuracy: 0.9114 - val_loss: 0.1521 - val_accuracy: 0.9560\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1658 - accuracy: 0.9527 - val_loss: 0.1273 - val_accuracy: 0.9678\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1363 - accuracy: 0.9629 - val_loss: 0.1098 - val_accuracy: 0.9729\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1242 - accuracy: 0.9681 - val_loss: 0.1038 - val_accuracy: 0.9747\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1178 - accuracy: 0.9711 - val_loss: 0.1106 - val_accuracy: 0.9731\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1115 - accuracy: 0.9727 - val_loss: 0.1037 - val_accuracy: 0.9756\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1067 - accuracy: 0.9739 - val_loss: 0.1102 - val_accuracy: 0.9756\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1009 - accuracy: 0.9763 - val_loss: 0.1062 - val_accuracy: 0.9768\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0984 - accuracy: 0.9773 - val_loss: 0.1119 - val_accuracy: 0.9773\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0929 - accuracy: 0.9788 - val_loss: 0.1151 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224071d1700>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#implemented by subclassing keras.callbacks.Callback\n",
    "\n",
    "#Create a loss history graph per batch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "  \n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "  \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "  \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []\n",
    "        \n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb0de83",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b8f826ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2921 - accuracy: 0.9138 - val_loss: 0.1561 - val_accuracy: 0.9563\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1653 - accuracy: 0.9540 - val_loss: 0.1355 - val_accuracy: 0.9656\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1450 - accuracy: 0.9612 - val_loss: 0.1116 - val_accuracy: 0.9711\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1249 - accuracy: 0.9674 - val_loss: 0.1240 - val_accuracy: 0.9718\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1202 - accuracy: 0.9707 - val_loss: 0.1131 - val_accuracy: 0.9752\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1119 - accuracy: 0.9731 - val_loss: 0.1025 - val_accuracy: 0.9748\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1070 - accuracy: 0.9743 - val_loss: 0.1018 - val_accuracy: 0.9788\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1049 - accuracy: 0.9756 - val_loss: 0.1103 - val_accuracy: 0.9777\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0973 - accuracy: 0.9768 - val_loss: 0.1191 - val_accuracy: 0.9773\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0935 - accuracy: 0.9790 - val_loss: 0.1148 - val_accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x223ca5b0400>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of how tensorboard is used\n",
    "import time\n",
    "NAME = \"TensorLogs-{}\".format(int(time.time()))\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "  \n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"C:/Users/joshu/Documents/TensorFlow Learning Materials/logs/{}\".format(NAME),\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91fcd945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d6c3a97626041990\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d6c3a97626041990\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Apparently there are no files for tensorboard to open which doesnt make sense. At least it shows up...\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir C:\\Users\\joshu\\Documents\\TensorFlow_Learning_Materials\\logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d62eb87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
